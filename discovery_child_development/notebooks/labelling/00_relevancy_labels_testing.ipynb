{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labelling relevant vs non-relevant data\n",
    "\n",
    "- Load the data\n",
    "- Define prompt\n",
    "- OpenAI function calling\n",
    "- Save the labels in a standard format\n",
    "- Keep track of data that's already labelled\n",
    "\n",
    "Open questions:\n",
    "- Shall we re-do the labelling at least twice to compare the results?\n",
    "- Alternatively, can shuffle the order of different categories to remove some bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from discovery_child_development.utils.openai_utils import client\n",
    "import json\n",
    "import random\n",
    "\n",
    "def create_category_description_string(categories: dict, randomise: bool=False) -> str:\n",
    "    \"\"\"Create the category descriptions for the prompt\n",
    "    \n",
    "    Args:\n",
    "        categories (Dict): The categories, in the format {category: description}\n",
    "        randomise (bool, optional): Whether to randomise the order of the categories. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        str: The category descriptions with each category and description in a new line\n",
    "    \"\"\"\n",
    "    category_descriptions = \"\"\n",
    "    all_categories = list(categories.keys())\n",
    "    if randomise:\n",
    "        all_categories = random.sample(all_categories, len(all_categories))\n",
    "    # randomise the order categories so that the order is not always the same\n",
    "    for category in all_categories:\n",
    "        category_descriptions += f\"{category}: {categories[category]}\\n\"\n",
    "    return category_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test texts\n",
    "texts = [\n",
    "    # relevant\n",
    "    \"A fun activity for babies aged 3-6 months to help development and language learning. Try blowing bubbles with your baby and see how they react. Talk to them about what they're seeing.\",\n",
    "    # non-relevant (child is too old)\n",
    "    \"A fun activity for 6 year old children to help development and language learning. Try blowing bubbles with your child and see how they react. Talk to them about what they're seeing.\",\n",
    "    # non-relevant (non human)\n",
    "    \"A fun activity for a piglet to help development and learning. Try blowing bubbles with your little one and see how they react. Talk to them.\",\n",
    "    # unclear (age not specified)\n",
    "    \"A fun activity for a child to help development and learning. Try blowing bubbles and see how they react. Talk to them.\",\n",
    "]\n",
    "\n",
    "category_descriptions = {\n",
    "    \"Relevant\": \"Text that describes an innovation, technology or aspect related to human child development and developmental needs, where the child is between 0 and 5 years old (including 5 year olds). If the age is not specified, texts about infants, babies, toddlers or preschool are also relevant.\",\n",
    "    \"Non-relevant\": \"Text about any other topic than child development, or if the children are too old (older than 5 years old and/or already going to school), or if the text is about non-human children.\",\n",
    "    \"Unclear\": \"Text that is about human child development and developmental needs, but the age of the children has not been explicitly specified.\"\n",
    "}\n",
    "\n",
    "categories = list(category_descriptions.keys())\n",
    "n_categories = len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant: Text that describes an innovation, technology or aspect related to human child development and developmental needs, where the child is between 0 and 5 years old (including 5 year olds). If the age is not specified, texts about infants, babies, toddlers or preschool are also relevant.\n",
      "Non-relevant: Text about any other topic than child development, or if the children are too old (older than 5 years old and/or already going to school), or if the text is about non-human children.\n",
      "Unclear: Text that is about human child development and developmental needs, but the age of the children has not been explicitly specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(create_category_description_string(category_descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "function = {\n",
    "    \"name\": \"predict_relevance\",\n",
    "    \"description\": \"Predict the relevance of a given text\",\n",
    "    \"parameters\": {\n",
    "           \"type\": \"object\",\n",
    "           \"properties\": {\n",
    "                  \"prediction\": {\n",
    "                         \"type\": \"string\",\n",
    "                         \"enum\": [\"Relevant\", \"Non-relevant\", \"Unclear\"],\n",
    "                         \"description\": \"The predicted relevance of the given text. Infer this from the provided relevance criteria.\"\n",
    "                  }\n",
    "             },\n",
    "             \"required\": [\"prediction\"]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = texts[3]\n",
    "prompt = {\"role\": \"user\", \"content\": f\"###Relevance criteria###\\nTexts can be categorised in the following {n_categories} categories.\\n{create_category_description_string(category_descriptions)}\\n\\n###Instructions###\\nCategorise the following text to one relevance category.\\n{text}\\n\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-29 13:04:24,263 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "r = client.chat.completions.create(\n",
    "   model=\"gpt-4\",\n",
    "   temperature=0.0,\n",
    "   messages=[prompt],\n",
    "   functions=[function],\n",
    "   function_call={\"name\": \"predict_relevance\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': 'Unclear'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(r.choices[0].message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing a test sample of Patents and OpenAlex data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from discovery_child_development.getters import openalex\n",
    "from discovery_child_development.utils.utils import load_jsonl\n",
    "from discovery_child_development.getters import patents\n",
    "import pandas as pd\n",
    "\n",
    "openalex_sample = \"data/relevance/relevance_openalex.jsonl\"\n",
    "patents_sample = \"data/relevance/relevance_patents.jsonl\"\n",
    "\n",
    "output_file = 'data/relevance/relevance_test_sample.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "openalex_df = openalex.get_abstracts()\n",
    "\n",
    "patents_df = (\n",
    "    patents.get_patents_from_s3()\n",
    "    .assign(text=lambda df: df[\"title\"] + \". \" + df[\"abstract\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_openalex = (\n",
    "    pd.DataFrame(load_jsonl(openalex_sample))\n",
    "    .assign(source='openalex')\n",
    "    .merge(openalex_df[['id', 'text']], how='left', on='id')\n",
    ")\n",
    "df_patents = (\n",
    "    pd.DataFrame(load_jsonl(patents_sample))\n",
    "    .assign(source='patents')\n",
    "    .merge(patents_df[['publication_number', 'text']].rename(columns={'publication_number': 'id'}), how='left', on='id')\n",
    ")\n",
    "df_labels = pd.concat([df_openalex, df_patents]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 10 random rows per each unique column of 'prediction' and 'source'\n",
    "def sample_labelled_data(df, n=10):\n",
    "    return df.groupby(['prediction', 'source']).apply(lambda x: x.sample(n)).reset_index(drop=True)\n",
    "\n",
    "sample_labelled_data(df_labels).to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1262"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not-relevant</td>\n",
       "      <td>openalex</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not-relevant</td>\n",
       "      <td>patents</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not-specified</td>\n",
       "      <td>openalex</td>\n",
       "      <td>68</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not-specified</td>\n",
       "      <td>patents</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>openalex</td>\n",
       "      <td>302</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>patents</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prediction    source   id  text\n",
       "0   Not-relevant  openalex  380   380\n",
       "1   Not-relevant   patents   94    94\n",
       "2  Not-specified  openalex   68    66\n",
       "3  Not-specified   patents  225   225\n",
       "4       Relevant  openalex  302   302\n",
       "5       Relevant   patents  193   193"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.groupby(['prediction', 'source']).count().reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from discovery_child_development import S3_BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nesta_ds_utils.loading_saving import S3\n",
    "\n",
    "S3.upload_obj(df_labels, S3_BUCKET, 'data/labels/afs_relevance/relevance_labels_20231212.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discovery_child_development",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
