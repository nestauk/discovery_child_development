{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from discovery_child_development import config, PROJECT_DIR\n",
    "from discovery_child_development.utils import jsonl_utils as jsonl\n",
    "from discovery_child_development.utils import taxonomy_labelling_utils as tlu\n",
    "from discovery_child_development.utils.openai_utils import client\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import tiktoken\n",
    "import wandb\n",
    "\n",
    "MODEL = \"gpt-3.5-turbo-1106\" # \"gpt-4\"\n",
    "\n",
    "def get_model_cost(model):\n",
    "    # based on https://openai.com/pricing\n",
    "    if model == \"gpt-3.5-turbo-1106\":\n",
    "        input = 0.001\n",
    "        output = 0.002\n",
    "    elif model == \"gpt-4\":\n",
    "        input = 0.03\n",
    "        output = 0.06\n",
    "    return input, output\n",
    "\n",
    "MODEL_INPUT_COST, MODEL_OUTPUT_COST = get_model_cost(MODEL)\n",
    "SEED = config[\"seed\"]\n",
    "\n",
    "random.seed(SEED)\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(MODEL)\n",
    "\n",
    "LABELS_PATH = PROJECT_DIR / \"inputs/data/labelling/taxonomy/output/training_validation_data_patents_openalex_LABELLED.jsonl\"\n",
    "PROMPT_OUT_PATH = PROJECT_DIR / \"inputs/data/labelling/taxonomy/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these functions came from: https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding=encoding):\n",
    "  return len(encoding.encode(string))\n",
    "\n",
    "def num_tokens_from_messages(messages, model=MODEL):\n",
    "    \"\"\"Return the number of tokens used by a list of messages.\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except KeyError:\n",
    "        print(\"Warning: model not found. Using cl100k_base encoding.\")\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    if model in {\n",
    "        \"gpt-3.5-turbo-0613\",\n",
    "        \"gpt-3.5-turbo-16k-0613\",\n",
    "        \"gpt-4-0314\",\n",
    "        \"gpt-4-32k-0314\",\n",
    "        \"gpt-4-0613\",\n",
    "        \"gpt-4-32k-0613\",\n",
    "        }:\n",
    "        tokens_per_message = 3\n",
    "        tokens_per_name = 1\n",
    "    elif model == \"gpt-3.5-turbo-0301\":\n",
    "        tokens_per_message = 4  # every message follows <|start|>{role/name}\\n{content}<|end|>\\n\n",
    "        tokens_per_name = -1  # if there's a name, the role is omitted\n",
    "    elif \"gpt-3.5-turbo\" in model:\n",
    "        print(\"Warning: gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0613\")\n",
    "    elif \"gpt-4\" in model:\n",
    "        print(\"Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-4-0613\")\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f\"\"\"num_tokens_from_messages() is not implemented for model {model}. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\"\n",
    "        )\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>accept</th>\n",
       "      <th>model</th>\n",
       "      <th>model_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W3087096886</td>\n",
       "      <td>Progesterone for prevention of preterm birth i...</td>\n",
       "      <td>openalex</td>\n",
       "      <td>[Prenatal]</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>[Prenatal]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CN-212193180-U</td>\n",
       "      <td>Intelligent terminal robot for early teaching ...</td>\n",
       "      <td>patents</td>\n",
       "      <td>[Robotics, Education]</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>[Robotics]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W3011309505</td>\n",
       "      <td>Gender Equality and Early Childhood Care in Pe...</td>\n",
       "      <td>openalex</td>\n",
       "      <td>[Gender equality, early childhood care, Peru, ...</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>[Gender equality, early childhood care, Peru, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W2985416374</td>\n",
       "      <td>Social Norms about Father Involvement and Wome...</td>\n",
       "      <td>openalex</td>\n",
       "      <td>[Labour market]</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>[Cognitive development]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W2952475031</td>\n",
       "      <td>Magical Realism and Augmented Reality. We desc...</td>\n",
       "      <td>openalex</td>\n",
       "      <td>[AR VR]</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>[AR VR]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                               text  \\\n",
       "0     W3087096886  Progesterone for prevention of preterm birth i...   \n",
       "1  CN-212193180-U  Intelligent terminal robot for early teaching ...   \n",
       "2     W3011309505  Gender Equality and Early Childhood Care in Pe...   \n",
       "3     W2985416374  Social Norms about Father Involvement and Wome...   \n",
       "4     W2952475031  Magical Realism and Augmented Reality. We desc...   \n",
       "\n",
       "     source                                             accept  \\\n",
       "0  openalex                                         [Prenatal]   \n",
       "1   patents                              [Robotics, Education]   \n",
       "2  openalex  [Gender equality, early childhood care, Peru, ...   \n",
       "3  openalex                                    [Labour market]   \n",
       "4  openalex                                            [AR VR]   \n",
       "\n",
       "                model                                       model_output  \n",
       "0  gpt-3.5-turbo-1106                                         [Prenatal]  \n",
       "1  gpt-3.5-turbo-1106                                         [Robotics]  \n",
       "2  gpt-3.5-turbo-1106  [Gender equality, early childhood care, Peru, ...  \n",
       "3  gpt-3.5-turbo-1106                            [Cognitive development]  \n",
       "4  gpt-3.5-turbo-1106                                            [AR VR]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data that has already been labelled using prodigy\n",
    "human_labels = pd.DataFrame(jsonl.load_jsonl(LABELS_PATH))[['id', 'text', 'source', 'accept', 'model', 'model_output']]\n",
    "human_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>accept</th>\n",
       "      <th>model</th>\n",
       "      <th>model_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W3087096886</td>\n",
       "      <td>Progesterone for prevention of preterm birth i...</td>\n",
       "      <td>openalex</td>\n",
       "      <td>[Prenatal]</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>Prenatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CN-212193180-U</td>\n",
       "      <td>Intelligent terminal robot for early teaching ...</td>\n",
       "      <td>patents</td>\n",
       "      <td>[Robotics, Education]</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>Robotics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W3011309505</td>\n",
       "      <td>Gender Equality and Early Childhood Care in Pe...</td>\n",
       "      <td>openalex</td>\n",
       "      <td>[Gender equality, early childhood care, Peru, ...</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>Gender equality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W3011309505</td>\n",
       "      <td>Gender Equality and Early Childhood Care in Pe...</td>\n",
       "      <td>openalex</td>\n",
       "      <td>[Gender equality, early childhood care, Peru, ...</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>early childhood care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W3011309505</td>\n",
       "      <td>Gender Equality and Early Childhood Care in Pe...</td>\n",
       "      <td>openalex</td>\n",
       "      <td>[Gender equality, early childhood care, Peru, ...</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                               text  \\\n",
       "0     W3087096886  Progesterone for prevention of preterm birth i...   \n",
       "1  CN-212193180-U  Intelligent terminal robot for early teaching ...   \n",
       "2     W3011309505  Gender Equality and Early Childhood Care in Pe...   \n",
       "2     W3011309505  Gender Equality and Early Childhood Care in Pe...   \n",
       "2     W3011309505  Gender Equality and Early Childhood Care in Pe...   \n",
       "\n",
       "     source                                             accept  \\\n",
       "0  openalex                                         [Prenatal]   \n",
       "1   patents                              [Robotics, Education]   \n",
       "2  openalex  [Gender equality, early childhood care, Peru, ...   \n",
       "2  openalex  [Gender equality, early childhood care, Peru, ...   \n",
       "2  openalex  [Gender equality, early childhood care, Peru, ...   \n",
       "\n",
       "                model          model_output  \n",
       "0  gpt-3.5-turbo-1106              Prenatal  \n",
       "1  gpt-3.5-turbo-1106              Robotics  \n",
       "2  gpt-3.5-turbo-1106       Gender equality  \n",
       "2  gpt-3.5-turbo-1106  early childhood care  \n",
       "2  gpt-3.5-turbo-1106                  Peru  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_labels = human_labels.explode('model_output')\n",
    "\n",
    "gpt_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AR VR',\n",
       " 'Assessment (general)',\n",
       " 'Child mental health',\n",
       " 'Child protection',\n",
       " 'Cognition',\n",
       " 'Cognitive development',\n",
       " 'Communication and language',\n",
       " 'Culture and communities',\n",
       " 'Data',\n",
       " 'Data Science and AI',\n",
       " 'Early childhood development (general)',\n",
       " 'Early childhood education',\n",
       " 'Early education',\n",
       " 'Early learning',\n",
       " 'Education',\n",
       " 'Emotional well-being',\n",
       " 'Environment',\n",
       " 'Expressive arts and design',\n",
       " 'Family environment',\n",
       " 'Games',\n",
       " 'Gender equality',\n",
       " 'Genetics',\n",
       " 'Health',\n",
       " 'Income',\n",
       " 'Inequalities',\n",
       " 'Internet',\n",
       " 'Kindergarten',\n",
       " 'Latin America',\n",
       " 'Literacy',\n",
       " 'Media',\n",
       " 'Mental health',\n",
       " 'Mobile',\n",
       " 'Neuroscience',\n",
       " 'Nutrition and weight',\n",
       " 'Operations',\n",
       " 'Personal social emotional',\n",
       " 'Peru',\n",
       " 'Physical',\n",
       " 'Policy',\n",
       " 'Pre-primary',\n",
       " 'Prenatal',\n",
       " 'Preschool',\n",
       " 'RCTs',\n",
       " 'Religious and moral values',\n",
       " 'Robotics',\n",
       " 'SDGs',\n",
       " 'SEND',\n",
       " 'Sleep',\n",
       " 'Social environment',\n",
       " 'Social media',\n",
       " 'Technology (general)',\n",
       " 'childcare services',\n",
       " 'developing countries',\n",
       " 'early childhood care',\n",
       " 'education',\n",
       " 'executive function',\n",
       " 'fiscally possible',\n",
       " 'gender inequality',\n",
       " 'memory',\n",
       " 'politically necessary',\n",
       " 'problem-solving',\n",
       " 'social programs',\n",
       " 'sustainable development',\n",
       " 'women']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(gpt_labels['model_output'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_flat = tlu.load_categories()\n",
    "\n",
    "function = tlu.format_function(categories_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_gpt_output(llm_output, human_output, id, text, model, prompt):\n",
    "    label_diff = len(llm_output) - len(human_output)\n",
    "    if label_diff < 0:\n",
    "        n_missing_labels = abs(label_diff)\n",
    "        n_extra_labels = 0\n",
    "    elif label_diff > 0:\n",
    "        n_extra_labels = label_diff\n",
    "        n_missing_labels = 0\n",
    "    else:\n",
    "        n_extra_labels = 0\n",
    "        n_missing_labels = 0\n",
    "        \n",
    "    return {\n",
    "          \"id\": id,\n",
    "          \"text\": text,\n",
    "          \"model\": model,\n",
    "           \"prompt\": prompt,\n",
    "           \"output\": llm_output,\n",
    "           \"human_output\": human_output,\n",
    "           \"exact_match\": llm_output == human_output,\n",
    "           \"no_overlap\": llm_output.isdisjoint(human_output),\n",
    "           \"label_diff\": label_diff,\n",
    "           \"n_extra_labels\": n_extra_labels,\n",
    "           \"n_missing_labels\": n_missing_labels\n",
    "        }\n",
    "    \n",
    "def summarise_gpt_performance(df):\n",
    "    exact_match = df['exact_match'].sum()\n",
    "    no_overlap = df['no_overlap'].sum()\n",
    "    prop_exact_matches = df['exact_match'].sum() / len(df)\n",
    "    n_missing_labels = df['n_missing_labels'].mean()\n",
    "    prop_no_overlap = df['no_overlap'].sum() / len(df)\n",
    "    return {'exact_matches': exact_match,\n",
    "            'no_overlap': no_overlap,\n",
    "            'prop_exact_matches': prop_exact_matches,\n",
    "            'avg_missing_labels': n_missing_labels,\n",
    "            'prop_no_overlap': prop_no_overlap}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse prodigy labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_labels_dict = human_labels[['id', 'text', 'accept', 'model','model_output']].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_matches': 36,\n",
       " 'no_overlap': 9,\n",
       " 'prop_exact_matches': 0.43902439024390244,\n",
       " 'avg_missing_labels': 0.6219512195121951,\n",
       " 'prop_no_overlap': 0.10975609756097561}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prodigy_results = []\n",
    "\n",
    "for row in human_labels_dict:\n",
    "    prodigy_results.append(eval_gpt_output(set(row['model_output']), set(row['accept']), row['id'], row['text'], row['model'], prompt=\"\"))\n",
    "\n",
    "df = pd.DataFrame(prodigy_results)\n",
    "\n",
    "summarise_gpt_performance(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare different models (you can also tweak the prompt and run this part again to see what changes)\n",
    "\n",
    "This code block also logs your prompt and key metrics on weights & biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-20 11:56:14,632 - wandb.jupyter - ERROR - Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrosie-oxbury\u001b[0m (\u001b[33mnesta-uk\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/rosie.oxbury/Documents/git_repos/discovery_child_development/discovery_child_development/notebooks/labelling/wandb/run-20231220_115615-f8vqg8ca</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nesta-uk/ISS%20supervised%20ML/runs/f8vqg8ca' target=\"_blank\">helpful-music-174</a></strong> to <a href='https://wandb.ai/nesta-uk/ISS%20supervised%20ML' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nesta-uk/ISS%20supervised%20ML' target=\"_blank\">https://wandb.ai/nesta-uk/ISS%20supervised%20ML</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nesta-uk/ISS%20supervised%20ML/runs/f8vqg8ca' target=\"_blank\">https://wandb.ai/nesta-uk/ISS%20supervised%20ML/runs/f8vqg8ca</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-20 11:56:21,844 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:56:23,428 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:56:24,321 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:56:26,086 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:56:28,954 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:56:30,592 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:56:32,846 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:56:34,792 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:56:38,171 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:56:39,019 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:56:40,629 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:56:43,148 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:56:45,445 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:56:47,009 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:56:49,638 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:56:51,142 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:56:52,197 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:56:54,045 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:56:56,033 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:56:57,728 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:56:59,879 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:03,214 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:05,741 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:08,004 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:09,126 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:10,328 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:13,605 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:16,164 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:18,128 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:19,022 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:21,708 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:23,947 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:24,887 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:26,401 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:28,962 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:30,193 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:31,320 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:32,372 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:34,742 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:35,822 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:38,590 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:39,718 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:41,662 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:43,593 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:44,839 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:46,444 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:48,034 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:49,238 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:50,161 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:52,106 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:53,027 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:54,663 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:55,998 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:56,858 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:58,149 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:57:59,683 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:58:01,322 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:58:03,705 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:58:05,922 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:58:06,954 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:58:08,535 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:58:09,821 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:58:10,969 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:58:13,610 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:58:14,839 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:58:16,487 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:58:17,820 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:58:20,174 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:58:22,109 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:58:24,567 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:58:26,839 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:58:28,050 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:58:29,074 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:58:30,097 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:58:33,320 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:58:34,705 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:58:36,036 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:58:38,084 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:58:41,103 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:58:42,283 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:58:43,994 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:58:45,047 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913e6adb183240038c62e1531b39cb51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.633 MB of 1.225 MB uploaded\\r'), FloatProgress(value=0.5161517761117138, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.29268</td></tr><tr><td>avg_missing_labels</td><td>0.89024</td></tr><tr><td>prop_no_overlap</td><td>0.17073</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">helpful-music-174</strong> at: <a href='https://wandb.ai/nesta-uk/ISS%20supervised%20ML/runs/f8vqg8ca' target=\"_blank\">https://wandb.ai/nesta-uk/ISS%20supervised%20ML/runs/f8vqg8ca</a><br/>Synced 7 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231220_115615-f8vqg8ca/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940c00720bf44bb7b5d70773681a8d67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011152832411203741, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/rosie.oxbury/Documents/git_repos/discovery_child_development/discovery_child_development/notebooks/labelling/wandb/run-20231220_115852-neq19amc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nesta-uk/ISS%20supervised%20ML/runs/neq19amc' target=\"_blank\">peachy-thunder-175</a></strong> to <a href='https://wandb.ai/nesta-uk/ISS%20supervised%20ML' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nesta-uk/ISS%20supervised%20ML' target=\"_blank\">https://wandb.ai/nesta-uk/ISS%20supervised%20ML</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nesta-uk/ISS%20supervised%20ML/runs/neq19amc' target=\"_blank\">https://wandb.ai/nesta-uk/ISS%20supervised%20ML/runs/neq19amc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-20 11:58:59,795 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:01,879 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:04,029 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:05,742 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:06,844 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:09,028 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:10,668 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:13,756 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:15,292 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:16,209 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:18,462 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:19,370 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:22,054 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:22,766 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:24,297 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:26,455 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:27,378 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:29,221 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:30,879 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:33,218 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:34,857 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:37,008 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:38,856 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:40,901 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:42,519 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:44,277 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:46,023 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:48,335 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:50,016 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:52,208 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:53,833 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:55,751 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:57,800 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 11:59:58,822 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:00,449 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:01,442 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:03,330 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:05,908 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:07,312 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:08,757 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:10,703 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:12,467 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:14,024 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:16,334 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:17,099 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:18,701 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:20,129 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:21,595 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:22,276 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:23,662 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:25,421 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:27,681 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:29,749 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:31,325 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:32,105 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:33,537 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:34,767 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:36,304 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:37,534 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:38,966 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:41,416 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:43,677 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:45,841 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:47,056 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:48,149 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:50,435 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:52,073 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:54,639 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:56,578 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:00:57,973 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:01:00,060 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:01:02,110 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:01:05,109 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:01:06,291 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:01:07,730 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:01:09,175 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:01:10,506 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:01:12,247 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:01:14,054 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:01:16,129 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:01:17,017 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-12-20 12:01:18,186 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f27a61395a4aa9a5cd3b82285b5758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.625 MB of 1.215 MB uploaded\\r'), FloatProgress(value=0.514537350859962, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.21951</td></tr><tr><td>avg_missing_labels</td><td>1.79268</td></tr><tr><td>prop_no_overlap</td><td>0.29268</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">peachy-thunder-175</strong> at: <a href='https://wandb.ai/nesta-uk/ISS%20supervised%20ML/runs/neq19amc' target=\"_blank\">https://wandb.ai/nesta-uk/ISS%20supervised%20ML/runs/neq19amc</a><br/>Synced 7 W&B file(s), 1 media file(s), 1 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231220_115852-neq19amc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = ['gpt-3.5-turbo-1106', 'gpt-4-0613']\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model in models:\n",
    "    run = wandb.init(\n",
    "                project=\"ISS supervised ML\",\n",
    "                job_type=\"Taxonomy labelling_prompt_engineering\",\n",
    "                save_code=True,\n",
    "                tags=[model],\n",
    "            )\n",
    "    results[model] = {}\n",
    "    results[model]['outputs'] = []\n",
    "    \n",
    "    # Create an artifact for the prompt\n",
    "    prompt_artifact = wandb.Artifact('prompt_artifact', type='text')\n",
    "    temp_prompt = tlu.build_prompt(\"<TEXT>\", categories_flat)\n",
    "    str_prompt = []\n",
    "    for m in temp_prompt:\n",
    "        str_prompt.append(f\"{m['role']}: {m['content']}\\n\")\n",
    "    str_prompt = ''.join(str_prompt)\n",
    "    with open(f\"{PROMPT_OUT_PATH}/prompt.txt\", \"w\") as file:\n",
    "        file.write(str_prompt)\n",
    "    prompt_artifact.add_file(f\"{PROMPT_OUT_PATH}/prompt.txt\")\n",
    "    # Log the artifact\n",
    "    wandb.log_artifact(prompt_artifact)\n",
    "    \n",
    "    for index, row in human_labels.iterrows():\n",
    "        prompt = tlu.build_prompt(row['text'], categories_flat)\n",
    "        r = client.chat.completions.create(\n",
    "            model=model,\n",
    "            temperature=0.0,\n",
    "            messages=prompt,\n",
    "            functions=[function],\n",
    "            function_call={\"name\": \"predict_category\"},\n",
    "            )\n",
    "        llm_output = set(tlu.get_labels_from_gpt_response(r))\n",
    "        human_labels_list = human_labels[human_labels['id'] == row['id']]['accept'].values\n",
    "        human_output = set([label for sublist in human_labels_list for label in sublist])\n",
    "        results[model]['outputs'].append(eval_gpt_output(llm_output, human_output, id=row['id'], text=row['text'], model=model, prompt=prompt))\n",
    "    df = pd.DataFrame(results[model]['outputs'])\n",
    "    wb_table = wandb.Table(\n",
    "                data=df, columns=df.columns\n",
    "            )\n",
    "    run.log({\"Outputs\": wb_table})\n",
    "    # Evaluation metrics\n",
    "    summary_stats = summarise_gpt_performance(df)\n",
    "    results[model]['stats'] = summary_stats\n",
    "    # Log metrics\n",
    "    wandb.run.summary[\"accuracy\"] = summary_stats['prop_exact_matches']\n",
    "    wandb.run.summary['prop_no_overlap'] = summary_stats['prop_no_overlap']\n",
    "    wandb.run.summary['avg_missing_labels'] = summary_stats['avg_missing_labels']\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>model</th>\n",
       "      <th>prompt</th>\n",
       "      <th>output</th>\n",
       "      <th>human_output</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>no_overlap</th>\n",
       "      <th>label_diff</th>\n",
       "      <th>n_extra_labels</th>\n",
       "      <th>n_missing_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W3087096886</td>\n",
       "      <td>Progesterone for prevention of preterm birth i...</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>[{'role': 'system', 'content': 'You are an exp...</td>\n",
       "      <td>{Prenatal}</td>\n",
       "      <td>{Prenatal}</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CN-212193180-U</td>\n",
       "      <td>Intelligent terminal robot for early teaching ...</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>[{'role': 'system', 'content': 'You are an exp...</td>\n",
       "      <td>{Robotics}</td>\n",
       "      <td>{Robotics, Education}</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W3011309505</td>\n",
       "      <td>Gender Equality and Early Childhood Care in Pe...</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>[{'role': 'system', 'content': 'You are an exp...</td>\n",
       "      <td>{Policy}</td>\n",
       "      <td>{Social services, Latin America, fiscally poss...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-15</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W2985416374</td>\n",
       "      <td>Social Norms about Father Involvement and Wome...</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>[{'role': 'system', 'content': 'You are an exp...</td>\n",
       "      <td>{Policy}</td>\n",
       "      <td>{Labour market}</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W2952475031</td>\n",
       "      <td>Magical Realism and Augmented Reality. We desc...</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>[{'role': 'system', 'content': 'You are an exp...</td>\n",
       "      <td>{Technology (general), Education, Media, AR VR...</td>\n",
       "      <td>{AR VR}</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                               text  \\\n",
       "0     W3087096886  Progesterone for prevention of preterm birth i...   \n",
       "1  CN-212193180-U  Intelligent terminal robot for early teaching ...   \n",
       "2     W3011309505  Gender Equality and Early Childhood Care in Pe...   \n",
       "3     W2985416374  Social Norms about Father Involvement and Wome...   \n",
       "4     W2952475031  Magical Realism and Augmented Reality. We desc...   \n",
       "\n",
       "                model                                             prompt  \\\n",
       "0  gpt-3.5-turbo-1106  [{'role': 'system', 'content': 'You are an exp...   \n",
       "1  gpt-3.5-turbo-1106  [{'role': 'system', 'content': 'You are an exp...   \n",
       "2  gpt-3.5-turbo-1106  [{'role': 'system', 'content': 'You are an exp...   \n",
       "3  gpt-3.5-turbo-1106  [{'role': 'system', 'content': 'You are an exp...   \n",
       "4  gpt-3.5-turbo-1106  [{'role': 'system', 'content': 'You are an exp...   \n",
       "\n",
       "                                              output  \\\n",
       "0                                         {Prenatal}   \n",
       "1                                         {Robotics}   \n",
       "2                                           {Policy}   \n",
       "3                                           {Policy}   \n",
       "4  {Technology (general), Education, Media, AR VR...   \n",
       "\n",
       "                                        human_output  exact_match  no_overlap  \\\n",
       "0                                         {Prenatal}         True       False   \n",
       "1                              {Robotics, Education}        False       False   \n",
       "2  {Social services, Latin America, fiscally poss...        False        True   \n",
       "3                                    {Labour market}        False        True   \n",
       "4                                            {AR VR}        False       False   \n",
       "\n",
       "   label_diff  n_extra_labels  n_missing_labels  \n",
       "0           0               0                 0  \n",
       "1          -1               0                 1  \n",
       "2         -15               0                15  \n",
       "3           0               0                 0  \n",
       "4           4               4                 0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results['gpt-3.5-turbo-1106']['outputs']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discovery_child_development",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
