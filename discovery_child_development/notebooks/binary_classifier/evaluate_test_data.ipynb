{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to evaluate the simple models (\"log_regression\", \"knn\", \"random_forest\", \"sgd\", \"svm\") and the distilbert-base-uncased models on the test data (labelled data not involved in the training process). To decide which model to use, we will use the accuracy score and the f1 score, primarily. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "from discovery_child_development import PROJECT_DIR, binary_config, config, S3_BUCKET\n",
    "from nesta_ds_utils.loading_saving import S3\n",
    "from discovery_child_development.utils.huggingface_pipeline import (\n",
    "    load_model,\n",
    "    load_training_args,\n",
    "    load_trained_model)\n",
    "from discovery_child_development.getters.binary_classifier.gpt_labelled_datasets import get_labelled_data_for_classifier\n",
    "from discovery_child_development.getters.binary_classifier.binary_classifier_model import get_binary_classifier_models\n",
    "from discovery_child_development.utils.testing_examples_utils import testing_examples_simple\n",
    "from discovery_child_development.utils.testing_examples_utils import testing_examples_huggingface\n",
    "from discovery_child_development.utils.general_utils import replace_binary_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Setting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model vars\n",
    "production = True\n",
    "\n",
    "# Set the seed\n",
    "SEED = config[\"seed\"]\n",
    "np.random.seed(SEED)\n",
    "\n",
    "#Paths\n",
    "S3_PATH = \"models/binary_classifier/\"\n",
    "PATH_TO = f\"{PROJECT_DIR}/outputs/data/models/\"\n",
    "MODEL_FILENAME = f\"gpt_labelled_binary_classifier_distilbert_production_{production}.tar.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Loading simple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_simple = [\"log_regression\", \"knn\", \"random_forest\", \"sgd\", \"svm\"]\n",
    "models_all = {}\n",
    "for model in models_simple:\n",
    "    # Save model to S3\n",
    "    models_all[model]=S3.download_obj(\n",
    "    bucket=S3_BUCKET,\n",
    "    path_from=f\"{S3_PATH}gpt_labelled_binary_classifier_{model}.pkl\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Loading Distilbert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_binary_classifier_models(filename=MODEL_FILENAME, s3_path=S3_PATH, path_to=PATH_TO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = f\"{PATH_TO}gpt_labelled_binary_classifier_distilbert_production_{production}\"\n",
    "# Load the model\n",
    "model = load_model(model_path=model_folder,config=binary_config, num_labels=2)\n",
    "\n",
    "# Train model with early stopping\n",
    "training_args = load_training_args(output_dir=S3_PATH, config=binary_config)\n",
    "trainer = load_trained_model(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    config=binary_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Collecting test data results for simple classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = get_labelled_data_for_classifier(set_type=\"test\")\n",
    "test_data.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = replace_binary_labels(\n",
    "        test_data, replace_cat=[\"Relevant\", \"Not-relevant\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df  = pd.DataFrame()\n",
    "metrics = ['method','accuracy', 'precision', 'recall', 'f1']\n",
    "for model in models_all:\n",
    "    temp_df = pd.DataFrame(testing_examples_simple(list(test_data.text),list(test_data.labels),models_all[model])[1], index=[0])\n",
    "    temp_df['method'] = model\n",
    "    temp_df = temp_df[metrics]\n",
    "    # Concat with results_df\n",
    "    results_df = pd.concat([results_df,temp_df],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Collecting test data results for distilbert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = testing_examples_huggingface(trainer,test_data[['labels','text']], binary_config)\n",
    "results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Distilbert results to results_df\n",
    "\n",
    "temp_df = pd.DataFrame(\n",
    "    {\n",
    "        \"method\": \"distilbert\",\n",
    "        \"accuracy\": results[1][\"test_accuracy\"],\n",
    "        \"precision\": results[1][\"test_precision\"],\n",
    "        \"recall\": results[1][\"test_recall\"],\n",
    "        \"f1\": results[1][\"test_f1\"],\n",
    "    },\n",
    "    index=[0],\n",
    ")\n",
    "\n",
    "# Concat with results_df\n",
    "results_df = pd.concat([results_df, temp_df], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Create figures from the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[\"method_names\"]= [\n",
    "    \"Logistic Regression\",\n",
    "    \"KNN\",\n",
    "    \"Random Forest\",\n",
    "    \"SGD\",\n",
    "    \"SVM\",\n",
    "    \"Distilbert\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 4 bar charts for each metric\n",
    "\n",
    "# Accuracy\n",
    "accuracy_plot = alt.Chart().mark_bar().encode(\n",
    "    x=alt.X(\"method_names\", title=\"Method\", axis=alt.Axis(labelAngle=45)),\n",
    "    y=alt.Y(\"accuracy\",title=\"Accuracy\"),\n",
    ").properties(width=200, height=200)\n",
    "\n",
    "# Precision\n",
    "precision_plot = alt.Chart().mark_bar().encode(\n",
    "    x=alt.X(\"method_names\", title=\"Method\", axis=alt.Axis(labelAngle=45)),\n",
    "    y=alt.Y(\"precision\",title=\"Precision\"),\n",
    ").properties(width=200, height=200)\n",
    "\n",
    "# Recall\n",
    "recall_plot = alt.Chart().mark_bar().encode(\n",
    "    x=alt.X(\"method_names\", title=\"Method\", axis=alt.Axis(labelAngle=45)),\n",
    "    y=alt.Y(\"recall\",title=\"Recall\"),\n",
    ").properties(width=200, height=200)\n",
    "\n",
    "# F1\n",
    "f1_plot = alt.Chart().mark_bar().encode(\n",
    "    x=alt.X(\"method_names\", title=\"Method\", axis=alt.Axis(labelAngle=45)),\n",
    "    y=alt.Y(\"f1\",title=\"F1\"),\n",
    ").properties(width=200, height=200)\n",
    "\n",
    "# Combine all charts in a 2x2 grid\n",
    "\n",
    "alt.vconcat(accuracy_plot | precision_plot, recall_plot | f1_plot,data=results_df).properties(title=\"Test data metrics\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the figure above we can see that the Distilbert model outperforms the others in all areas apart from Precision. Therefore, we will choose the distilbert model for our final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discovery_child_development",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
