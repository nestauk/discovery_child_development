{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Simple Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269159e4",
   "metadata": {},
   "source": [
    "The goal of this notebook is to train simple classifiers on the gpt-labelled openalex/patents and then test them on further data. We will use the following classifiers:\n",
    "\n",
    "* Logistic Regression\n",
    "* K-Nearest Neighbors\n",
    "* Random Forest\n",
    "* SGD Classifier\n",
    "* Support Vector Machine\n",
    "\n",
    "The embeddings are generated using the \"all-MiniLM-L6-v2\" sentence-transformer model. \n",
    "\n",
    "The equivalent refactored file resides in pipeline/models/binary_classifier. This notebook is for testing purposes only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f9e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cca70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nesta DS utils\n",
    "from nesta_ds_utils.loading_saving import S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3826ba76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import from project\n",
    "from discovery_child_development import PROJECT_DIR, logging, config, S3_BUCKET\n",
    "from discovery_child_development.utils import classification_utils\n",
    "from discovery_child_development.utils.general_utils import replace_binary_labels\n",
    "from discovery_child_development.getters.binary_classifier.gpt_labelled_datasets import (\n",
    "    get_labelled_data_for_classifier,\n",
    ")\n",
    "from discovery_child_development.getters.openalex import get_sentence_embeddings\n",
    "from discovery_child_development.getters.binary_classifier.prompts_edge_cases import get_examples\n",
    "from discovery_child_development.utils.testing_examples_utils import testing_examples_simple\n",
    "from discovery_child_development.utils.general_utils import replace_binary_labels\n",
    "from discovery_child_development.utils import wandb as wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c7ac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d77c014",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = PROJECT_DIR / \"outputs/models/\"\n",
    "S3_PATH = \"models/binary_classifier/\"\n",
    "\n",
    "PATH_FROM = \"data/labels/binary_classifier/processed/\"\n",
    "VECTORS_PATH = \"data/labels/binary_classifier/vectors/\"\n",
    "VECTORS_FILE = \"sentence_vectors_384_labelled.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cce8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the seed\n",
    "SEED = config[\"seed\"]\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMS\n",
    "wandb_run = False\n",
    "save_model = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f67d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_text_training = get_labelled_data_for_classifier(\n",
    "        set_type=\"train\", path_from=PATH_FROM\n",
    ")\n",
    "labelled_text_validation = get_labelled_data_for_classifier(\n",
    "        set_type=\"validation\", path_from=PATH_FROM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = get_examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setting up training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acabc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings from all-MiniLM-L6-v2\n",
    "embeddings_all = get_sentence_embeddings(\n",
    "        s3_bucket=S3_BUCKET, filepath=VECTORS_PATH, filename=VECTORS_FILE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6f2463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and validation sets\n",
    "training_set = labelled_text_training.merge(embeddings_all, on=\"id\", how=\"left\")\n",
    "validation_set = labelled_text_validation.merge(embeddings_all, on=\"id\", how=\"left\")\n",
    "training_set = replace_binary_labels(training_set, replace_cat=[\"Relevant\",\"Not-relevant\"])\n",
    "validation_set = replace_binary_labels(validation_set, replace_cat=[\"Relevant\",\"Not-relevant\"])\n",
    "\n",
    "# Setting up the training and validation sets\n",
    "X_train = training_set[\"miniLM_384_vector\"].apply(pd.Series).values\n",
    "X_val = validation_set[\"miniLM_384_vector\"].apply(pd.Series).values\n",
    "\n",
    "Y_train = training_set[\"labels\"]\n",
    "Y_val = validation_set[\"labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training and evaluating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_simple = [\"log_regression\", \"knn\", \"random_forest\", \"sgd\", \"svm\"]\n",
    "if not save_model:\n",
    "    models_all = {}\n",
    "for model in models_simple:\n",
    "    # Initialise wandb run\n",
    "    if wandb_run:\n",
    "        # Initialize a wandb run\n",
    "        run = wandb.init(\n",
    "            project=\"ISS supervised ML\",\n",
    "            job_type=\"Binary classifier - base models\",\n",
    "            save_code=True,\n",
    "            tags=[\"gpt-labelled\", \"all-MiniLM-L6-v2\", model, \"openealex/patents\"],\n",
    "        )\n",
    "        # Add reference to this data in wandb\n",
    "        wb.add_ref_to_data(\n",
    "            run=run,\n",
    "            name=\"binary_train_data_raw\",\n",
    "            description=f\"Binary classifier training data\",\n",
    "            bucket=S3_BUCKET,\n",
    "            filepath=f\"{PATH_FROM}gpt_labelled_train.csv\",\n",
    "        )\n",
    "        \n",
    "    # Creating the classifier\n",
    "    if model == \"log_regression\":\n",
    "        classifier = LogisticRegression(penalty=\"l2\", random_state=SEED)\n",
    "    elif model == \"knn\":\n",
    "        classifier = KNeighborsClassifier()\n",
    "    elif model == \"random_forest\":\n",
    "        classifier = RandomForestClassifier(random_state=SEED)\n",
    "    elif model == \"sgd\":\n",
    "        classifier = SGDClassifier(random_state=SEED)\n",
    "    elif model == \"svm\":\n",
    "        classifier = LinearSVC(random_state=SEED)\n",
    "\n",
    "    # Fitting the model\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    # Predicting on the validation set\n",
    "    predictions = classifier.predict(X_val)\n",
    "\n",
    "    # Creating metrics\n",
    "    metrics = classification_utils.create_average_metrics(\n",
    "    Y_val, predictions, average=\"binary\"\n",
    "    )\n",
    "    logging.info(metrics)\n",
    "\n",
    "    if save_model:\n",
    "        # Save model to S3\n",
    "        S3.upload_obj(\n",
    "        obj=classifier,\n",
    "        bucket=S3_BUCKET,\n",
    "        path_to=f\"{S3_PATH}gpt_labelled_binary_classifier_{model}.pkl\",\n",
    "        )\n",
    "    else:\n",
    "        models_all[model] = classifier\n",
    "\n",
    "    if wandb_run:\n",
    "        # Log metrics\n",
    "        wandb.run.summary[\"f1\"] = metrics[\"f1\"]\n",
    "        wandb.run.summary[\"accuracy\"] = metrics[\"accuracy\"]\n",
    "        wandb.run.summary[\"precision\"] = metrics[\"precision\"]\n",
    "        wandb.run.summary[\"recall\"] = metrics[\"recall\"]\n",
    "\n",
    "        # Adding reference to this model in wandb\n",
    "        wb.add_ref_to_data(\n",
    "            run=run,\n",
    "            name=f\"binary_classifier_{model}\",\n",
    "            description=f\"{model} model trained on binary classifier training data\",\n",
    "            bucket=S3_BUCKET,\n",
    "            filepath=f\"{S3_PATH}gpt_labelled_binary_classifier_{model}.pkl\",\n",
    "        )\n",
    "\n",
    "        # End the weights and biases run\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Trialing some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Not-specified\n",
    "examples = examples.query(\"labels!='Not specified'\")\n",
    "examples = replace_binary_labels(examples, replace_cat=[\"Relevant\",\"Not relevant\"])\n",
    "examples.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_examples_simple(list(examples.text),list(examples.labels),models_all[\"log_regression\"])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "comment_magics": true,
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "discovery_child_development",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
