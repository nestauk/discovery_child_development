# %% [markdown]
# This notebook is for preprocessing the Openlex data we have extracted and turning it into a format that can be the input to some text clustering.
#
# The data was generated by running `discovery_child_development/pipeline/openalex_workflow.py` from the command line via
# ```
# python discovery_child_development/pipeline/openalex_workflow.py run --production=True
# ```

# %%
import json
import os
import boto3
from dotenv import load_dotenv
import pandas as pd

# %%
filename = "openalex-works_production-True_concept-C109260823|C2993937534|C2777082460|C2911196330|C2993037610|C2779415726|C2781192327|C15471489|C178229462|C138496976_year-2023.json"

# %%
load_dotenv()
# Bucket where the file is saved
S3_BUCKET = os.environ["S3_BUCKET"]
# subfolder within the bucket
S3_PATH = "metaflow"

filepath = f"{S3_PATH}/{filename}"

# %%
# Loading the data may take a few minutes because there are ~70,000 works and the file is ~800MB
s3_client = boto3.client("s3")
response = s3_client.get_object(Bucket=S3_BUCKET, Key=filepath)
openalex_raw_data = response["Body"].read().decode("utf-8")  # Convert bytes to string


# %%
# Convert it to a list format
openalex_data = json.loads(openalex_raw_data)
len(openalex_data)

# %%
# Inspect the first item to check that it looks as expected!
openalex_data[0]["concepts"]

# %% [markdown]
# # Concepts
#
# Create a dataframe that records all the concepts (concept IDs and names, concept level, wikidata, relevance score) for each work ID.

# %%
data_list = []

for work in openalex_data:
    for concept in work["concepts"]:
        data_list.append(
            {
                "openalex_id": work["id"],
                "title": work["title"],
                "concept_id": concept["id"],
                "wikidata": concept["wikidata"],
                "display_name": concept["display_name"],
                "level": concept["level"],
                "score": concept["score"],
            }
        )

# %%
df = pd.DataFrame(data_list)
df.head(20)

# %%
len(df)

# %% [markdown]
# The code below groups by concept name and sums up the relevance score across all works within each concept. The output is kind of surprising because we used a lot of child-related concepts to retrieve the data, but none of those show up in the top 20 concepts. It may be because the child-related concepts are lower level, while the inclusion of "Developmental Psychology", which is a higher level concept, within our starter list of concepts means that because we got all the works related to developmental psychology, these have swamped the child-related papers.

# %%
grouped_df = (
    df.groupby("display_name")
    .agg({"score": "sum"})
    .reset_index()
    .sort_values(by="score", ascending=False)
)

grouped_df.head(20)

# %%
from io import StringIO

csv_buffer = StringIO()
df.to_csv(csv_buffer)
s3_resource = boto3.resource("s3")
s3_resource.Object(
    S3_BUCKET,
    f"inputs/data/openAlex/concepts/concepts_metadata_C109260823|C2993937534|C2777082460|C2911196330|C2993037610|C2779415726|C2781192327|C15471489|C178229462|C138496976_year-2023.csv",
).put(Body=csv_buffer.getvalue())

# %%

# %%

# %%
