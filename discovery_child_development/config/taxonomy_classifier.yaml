# Training arguments
learning_rate: 0.00002
per_device_train_batch_size: 16
per_device_eval_batch_size: 16
gradient_accumulation_steps: 2
num_train_epochs: 30
weight_decay: 0
evaluation_strategy: "epoch"
save_strategy: "epoch"
metric_for_best_model: "f1"
load_best_model_at_end: True
early_stopping_patience: 2

# Type of problem for the classifier
problem_type: "multi_label_classification"
