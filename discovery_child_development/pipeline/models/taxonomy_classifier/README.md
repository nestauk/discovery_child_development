# Taxonomy classifier training pipeline

The input for this pipeline is labelled data generated with GPT. The output is a trained classifier that can be used to classify new texts into the taxonomy.

Relevant filepaths and hyperparameters can be found in `discovery_child_development/config/taxonomy_classifier.yaml`.

The scripts should be run in this order:

- `01_train_test_split.py` - splits the labelled texts into train, test and validation sets.
- `02a_sentence_embeddings.py` - uses `all-miniLM-L6-v2` to generate sentence embeddings for the train, test and validation sets.
- `02b_prep_hf_dataset.py` - uses functions from `discovery_child_development/utils/huggingface_pipeline.py` to prepare HuggingFace datasets for training and evaluation.
- `03_set_baseline.py` - using the sentence embeddings generated by 02a, trains a dummy classifier and logs the metrics on weights and biases. This establishes a baseline for different ML approaches we might want to try.
- `04a_train_simple_classifiers.py` - **TODO**
- `04b_finetune_distilbert.py` - fine-tunes `distilbert-base-uncased` using the datasets generated by 02b.
